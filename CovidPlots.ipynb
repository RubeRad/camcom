{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python, Jupyter, Pandas, and Matplotlib\n",
    "This is a Jupyter Python notebook, which is a collection of cells. Each cell is either of type 'markdown' (formatted text, like this cell) or code (python, grey background). The two most important rules of Jupyter Notebooks are:\n",
    "1. ***SHIFT-ENTER*** will cause the current cell to execute. \n",
    "  - For Markdown cells, 'execute' means render the formatting. ([Here's a markdown cheatsheet](https://sqlbak.com/blog/wp-content/uploads/2020/04/Jupyter-Notebook-Markdown-Cheatsheet.pdf))\n",
    "  - For Code cells, 'execute' means run the python.\n",
    "  - Some Code cells take a while to execute, watch for the * to change to a number\n",
    "1. Any cell can be edited (double-click into it) and re-executed (SHIFT-ENTER again).\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first code in any Python script/Jupyter notebook, needs to import any libraries that will be used. The `as` directives allow specification of nicknames that are more convenient to type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This next line is a special command for making plots look better in Jupyter notebooks\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt  # This is for creating graphs\n",
    "import pandas            as pd   # This greatly simplifies handling of tabular (csv) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` function `read_csv()` can read .csv files on your computer, but it's so smart it can even slurp in a .csv directly from online. This reads in the csv data linked to on this page: https://ourworldindata.org/coronavirus-source-data). \n",
    "\n",
    "It takes a few seconds to download, watch for the `*` to change to a number. \n",
    "\n",
    "Two two most important terms in the grammar of pandas are `Series` and `DataFrame`. A `DataFrame` is equivalent to  one tab of a spreadsheet (or one worksheet of a workbook). Each column of the `DataFrame` is one `Series`. The data object returned by `read_csv()` is held in a variable named `df` which stands for `DataFrame`.\n",
    "\n",
    "Note: Python is happy with specifying text constants (strings) with either single or double quotes, but single are preferred because they read cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing you can do it Jupyter Notebooks that you can't do in regular Python scripts (programs), is to just mention something at the end of a code cell, which is a request for the notebook to display it. If it's too big to be printed completely, it will be automatically summarized. For starters, you can try to get a glimpse of the whole `DataFrame` object itself. The `NaN` ('not a number') are empty cells in the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few more ways to describe/understand the data, execute each cell and take a minute to read and understand what information is provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape     # note this is a 'data member', a variable that belongs to every data frame. (Rows, Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns   # pandas assumes the first row of the csv are column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Python, anything after a hash is a comment, ignored as code, but for the benefit of the reader\n",
    "\n",
    "# This is a 'class function', so it needs (); sometimes input parameters go in there.\n",
    "df.info() # Data size, column headers, counts, and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # some common statistics on each column, note you can scroll to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # first few rows of data (default 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10) # last few rows of data (we specify 10 here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any individual `Series` can be fetched out of the data frame using square brackets, and some of the same functions apply, as well as a few others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_code'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_code'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_code'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Go back into those cells above, and edit to investigate some other Series, like 'location', 'date', 'new_cases'\n",
    "\n",
    "'value_counts()' has different top numbers for `iso_code` vs `location` vs `date`. What does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting date strings to date-type objects\n",
    "The `Series` 'date' looks like dates to us humans, but right now it is actually just text. Examine this difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be important for our matplotlib timeseries plots for this Series to be dates instead of text. Instead of typing the extra 'pd.to_datetime' every time, we can modify this data for good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date'].describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Slicing/Filtering\n",
    "A smaller `DataFrame` can be created from `Series` of your choosing. As always in Python, take careful note of the syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[  ['iso_code', 'location', 'date', 'new_cases', 'new_deaths', 'total_cases', 'new_cases_smoothed_per_million', 'new_deaths_smoothed_per_million']  ]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` can be 'sliced' (filtered) based on conditions applied to the data. These actions can be read something like \"The new variable USA is a `DataFrame` made from df2 by selecting all the rows for which the 'iso_code' is equal to the text constant 'USA'\"\n",
    "\n",
    "**Critically important Python NOTE:** One = means the action **assignment**, whatever is on the right, put it into the left. It is the same as Snap's `Set <variable> to <value>` from the  yellow Variables tab.  Two == means the **question** *are these two things the same* (or in this context, *where* are these two the same?), and is equivalent to the Predicate = in Snap!, from the green Operators tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA = df2[ df2['iso_code'] == 'USA' ]\n",
    "ITA = df2[ df2['iso_code'] == 'ITA' ]\n",
    "SWE = df2[ df2['iso_code'] == 'SWE' ]\n",
    "KOR = df2[ df2['iso_code'] == 'KOR' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to try various looks at these sliced DataFrames, like USA.info() or SWE.tail(), etc.\n",
    "USA.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Pandas Series' with MATPLOTLIB\n",
    "Now that we have a handle on manipulating csv data with pandas, we turn to the main point, which is to be able to visualize the data graphically. Here's a naive plot to start with. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAx = USA['date']       # grab the date       Series out of the USA DataFrame into a variable called USAx\n",
    "USAy = USA['new_deaths'] # grab the new_deaths Series out of the USA DataFrame into a variable called USAy\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(USAx, USAy)\n",
    "plt.plot(ITA['date'], ITA['new_deaths']) # The same can be done inside the plot command\n",
    "plt.plot(SWE['date'], SWE['new_deaths'])\n",
    "plt.plot(KOR['date'], KOR['new_deaths'])\n",
    "plt.legend(['USA', 'Italy', 'Sweden', 'South Korea'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, those curves are obviously incomparable because of quite different country populations. We can convert to per-million by applying arithmetic to the whole series (requires knowledge of the country population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA['new_deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA['new_deaths'] / 330000000   # USA population is about 350M, so this is per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA['new_deaths'] / 330000000 * 1000000  # per capita is too small, so scale up to per million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the above plot, except scaling per million (USA~331M, etc)\n",
    "USAperM = USA['new_deaths']/331\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(USAx, USAperM)\n",
    "plt.plot(ITA['date'], ITA['new_deaths']/60) # again, all this can be done inline\n",
    "plt.plot(SWE['date'], SWE['new_deaths']/10)\n",
    "plt.plot(KOR['date'], KOR['new_deaths']/51)\n",
    "plt.legend(['USA', 'Italy', 'Sweden', 'South Korea'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's smooth out those weekly cycles with a 7-day average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAperMrollWeek = USAperM.rolling(window=7) # this tracks statistics on a rolling window of 7 rows (days)\n",
    "USAperMweekAvg  = USAperMrollWeek.mean()    # this grabs the mean() (average), as opposed to min/max/med, etc.\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(USAx, USAperMweekAvg)\n",
    "plt.plot(ITA['date'], ITA['new_deaths'].rolling(window=7).mean()/60)  # These inlines are starting to get \n",
    "plt.plot(SWE['date'], SWE['new_deaths'].rolling(window=7).mean()/10)  #    unmanageably complex\n",
    "plt.plot(KOR['date'], KOR['new_deaths'].rolling(window=7).mean()/51)\n",
    "plt.legend(['USA', 'Italy', 'Sweden', 'South Korea'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Optional extra: Shifted Dates\n",
    "\n",
    "Most complicated, we can see that these curves would be more comparable if they were date-shifted, to reflect the different times when the pandemic hit different countries. A common technique is to line them all up based on when they had a certain common minimum number of cases, say 10. We will filter on a condition again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I could just type 100 in every line below, but this way if I want to experiment with a different value\n",
    "# I can edit just 1 line, instead of having to edit a line for every country (especially as countries are added)\n",
    "min_cases = 1000\n",
    "USAsh = USA[ USA['total_cases'] >= min_cases ]  # 'sh' for shift\n",
    "ITAsh = ITA[ ITA['total_cases'] >= min_cases ]\n",
    "SWEsh = SWE[ SWE['total_cases'] >= min_cases ]\n",
    "KORsh = KOR[ KOR['total_cases'] >= min_cases ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAsh['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAsh['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITAsh['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAsh['date'].min() - ITAsh['date'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see above that Italy reached 100 cases on Feb 24, 8 days before the US on Mar 3. (And that date objects can be subtracted!)\n",
    "\n",
    "Just like we were able to simply multiply and divide the entire 'new_deaths' Series by constant numbers, we can modify the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAt0 = USAsh['date'].min()\n",
    "ITAt0 = ITAsh['date'].min()\n",
    "SWEt0 = SWEsh['date'].min()\n",
    "KORt0 = KORsh['date'].min()\n",
    "\n",
    "USAsh['date'] - USAt0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAshX = USAsh['date'] - USAt0\n",
    "USAshY = USAsh['new_deaths'].rolling(window=7).mean()/331\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(USAshX, USAshY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that plot goes from 0 to 2.5e16. Even though the description of `USAsh['date'] - USAt0` above says 'days', matplotlib is interpreting it as milliseconds. We can fix this by forcing conversion to days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAshX = (USAsh['date'] - USAt0).astype('timedelta64[D]')\n",
    "USAshX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(USAshX, USAshY)\n",
    "plt.plot((ITAsh['date']-ITAt0).astype('timedelta64[D]'), ITAsh['new_deaths'].rolling(window=7).mean()/60)  \n",
    "plt.plot((SWEsh['date']-SWEt0).astype('timedelta64[D]'), SWEsh['new_deaths'].rolling(window=7).mean()/10) \n",
    "plt.plot((KORsh['date']-KORt0).astype('timedelta64[D]'), KORsh['new_deaths'].rolling(window=7).mean()/51)\n",
    "plt.legend(['USA', 'Italy', 'Sweden', 'South Korea'])\n",
    "plt.xlim( (0, 300) )\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

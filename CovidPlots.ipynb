{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Python, Jupyter, Pandas, and Matplotlib\n",
    "This is a Jupyter Python notebook, which is a collection of cells. Each cell is either of type 'markdown' (formatted text, like this cell) or code (python, grey background). The two most important rules of Jupyter Notebooks are:\n",
    "1. ***SHIFT-ENTER*** will cause the current cell to execute. \n",
    "  - For Markdown cells, 'execute' means render the formatting. ([Here's a markdown cheatsheet](https://sqlbak.com/blog/wp-content/uploads/2020/04/Jupyter-Notebook-Markdown-Cheatsheet.pdf))\n",
    "  - For Code cells, 'execute' means run the python.\n",
    "  - Some Code cells take a while to execute, watch for the * to change to a number\n",
    "1. Any cell can be edited (double-click into it) and re-executed (SHIFT-ENTER again).\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first code in any Python script/Jupyter notebook, needs to import any libraries that will be used. The `as` directives allow specification of nicknames that are more convenient to type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # This is for creating graphs\n",
    "import pandas            as pd   # This greatly simplifies handling of tabular (csv) data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` function `read_csv()` can read .csv files on your computer, but it's so smart it can even slurp in a .csv directly from online. This reads in the csv data linked to on this page: https://ourworldindata.org/coronavirus-source-data). \n",
    "\n",
    "It takes a few seconds to download, watch for the `*` to change to a number. \n",
    "\n",
    "Two two most important terms in the grammar of pandas are `Series` and `DataFrame`. A `DataFrame` is equivalent to  one tab of a spreadsheet (or one worksheet of a workbook). Each column of the `DataFrame` is one `Series`. The data object returned by `read_csv()` is held in a variable named `df` which stands for `DataFrame`.\n",
    "\n",
    "Note: Python is happy with specifying text constants (strings) with either single or double quotes, but single are preferred because they read cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://covid.ourworldindata.org/data/owid-covid-data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing you can do it Jupyter Notebooks that you can't do in regular Python scripts (programs), is to just mention something at the end of a code cell, which is a request for the notebook to display it. If it's too big to be printed completely, it will be automatically summarized. For starters, you can try to get a glimpse of the whole `DataFrame` object itself. The `NaN` ('not a number') are empty cells in the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few more ways to describe/understand the data, execute each cell and take a minute to read and understand what information is provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape     # note shape is a 'data member', a variable that belongs to every data frame. (Rows, Columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns   # pandas assumes the first row of the csv are column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info is a 'class function', so it needs (); sometimes input parameters go in there.\n",
    "df.info() # Data size, column headers, counts, and types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # some common statistics on each column, note you can scroll to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # first few rows of data (default 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10) # last few rows of data (we specify 10 here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any individual `Series` can be fetched out of the data frame using square brackets, and some of the same functions apply, as well as a few others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_code'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_code'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_code'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['iso_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Go back into those cells above, and edit to investigate some other Series, like 'location', 'date', 'new_cases'\n",
    "\n",
    "'value_counts()' has different top numbers for `iso_code` vs `location` vs `date`. What does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting date strings to date-type objects\n",
    "The `Series` 'date' looks like dates to us humans, but right now it is actually just text. Examine this difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be important for our matplotlib timeseries plots for this Series to be dates instead of text. Instead of typing the extra 'pd.to_datetime' every time, we can modify this data for good:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['date'].describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Slicing/Filtering\n",
    "A smaller `DataFrame` can be created from any group of `Series` that you choose. As always in Python, take careful note of the syntax, with `[]` inside `[]`, and quotes and commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's call this smaller DataFrame df6, because we're selecting 6 columns of interest\n",
    "df6 = df[  ['iso_code', 'location', 'date', 'new_cases', 'new_deaths', 'total_cases']  ]\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataFrame` can be 'sliced' (filtered) based on conditions applied to the data. These actions can be read something like \"The new variable USA is a `DataFrame` made from df6 by selecting all the rows for which the 'iso_code' is equal to the text constant 'USA'\"\n",
    "\n",
    "**Critically important Python NOTE:** One = means the action **assignment**, whatever is on the right, put it into the left. It is the same as Snap's `Set <variable> to <value>` from the  yellow Variables tab.  Two == means the **question** *are these two things the same* (or in this context, *where* are these two the same?), and is equivalent to the Predicate = in Snap!, from the green Operators tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA = df6[ df6['iso_code'] == 'USA' ] # Set variable USA to the DataFrame of the rows of df6 with iso_code==USA\n",
    "ITA = df6[ df6['iso_code'] == 'ITA' ]\n",
    "SWE = df6[ df6['iso_code'] == 'SWE' ]\n",
    "KOR = df6[ df6['iso_code'] == 'KOR' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to try various looks at these sliced DataFrames, like USA.info() or SWE.tail(), etc.\n",
    "USA.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Pandas Series' with MATPLOTLIB\n",
    "Now that we have a handle on manipulating csv data with pandas, we turn to the main point, which is to be able to visualize the data graphically. Here's a naive plot to start with. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAx = USA['date']       # grab the Series 'date'       out of the USA DataFrame into a variable called USAx\n",
    "USAy = USA['new_cases'] # grab the Series 'new_cases' out of the USA DataFrame into a variable called USAy\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(USAx, USAy)\n",
    "plt.plot(ITA['date'], ITA['new_cases']) # The same can be done inside the plot command\n",
    "plt.plot(SWE['date'], SWE['new_cases'])\n",
    "plt.plot(KOR['date'], KOR['new_cases'])\n",
    "plt.legend(['USA', 'Italy', 'Sweden', 'South Korea'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, those curves are obviously incomparable because of quite different country populations. We can convert to per-million by applying arithmetic to the whole series (requires knowledge of the country population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA['new_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA['new_cases'] / 330000000   # USA population is about 330M, so this is per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USA['new_cases'] / 330000000 * 1000000  # per capita is too small, so scale up to per million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the above plot, except scaling per million (USA~331M, etc)\n",
    "USAperM = USA['new_cases']/331\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(USAx, USAperM)\n",
    "plt.plot(ITA['date'], ITA['new_cases']/60) # again, all this can be done inline\n",
    "plt.plot(SWE['date'], SWE['new_cases']/10)\n",
    "plt.plot(KOR['date'], KOR['new_cases']/51)\n",
    "plt.legend(['USA', 'Italy', 'Sweden', 'South Korea'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's smooth out those weekly cycles with a 7-day average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAperMrollWeek = USAperM.rolling(window=7) # this tracks statistics on a rolling window of 7 rows (days)\n",
    "USAperMweekAvg  = USAperMrollWeek.mean()    # this grabs the mean() (average), as opposed to min/max/med, etc.\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(USAx, USAperMweekAvg)\n",
    "plt.plot(ITA['date'], ITA['new_cases'].rolling(window=7).mean()/60)  # These inlines are starting to get \n",
    "plt.plot(SWE['date'], SWE['new_cases'].rolling(window=7).mean()/10)  #    unmanageably complex\n",
    "plt.plot(KOR['date'], KOR['new_cases'].rolling(window=7).mean()/51)\n",
    "plt.legend(['USA', 'Italy', 'Sweden', 'South Korea'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Modify this notebook to make the following changes:\n",
    "\n",
    "1. Remove S. Korea (they did so well, they can barely be seen on the graph!)\n",
    "1. Add **TWO** countries of your choosing that make this graph more interesting (note you'll have to google the population of those two new countries)\n",
    "1. For those same countries, also make the graph of deaths per million (so far this has all been cases) \n",
    "\n",
    "Here is a table that you might find helpful (but you don't have to pick from these)\n",
    "\n",
    "|iso_code  | location |\n",
    "|:---------|:---------|\n",
    "|AUS       | Australia|\n",
    "|BRA       | Brazil   |\n",
    "|CAN       | Canada   |\n",
    "|ESP       | Spain    |\n",
    "|FRA       | France   |\n",
    "|GBR       | United Kingdom |\n",
    "|IRN       | Iran     |\n",
    "|ISR       | Israel   |\n",
    "|MEX       | Mexico   |\n",
    "|NZL       | New Zealand |\n",
    "|RUS       | Russia   |\n",
    "|ZAF       | South Africa |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Optional extra: Shifted Dates\n",
    "\n",
    "Most complicated, we can see that these curves would be more comparable if they were date-shifted, to reflect the different times when the pandemic hit different countries. A common technique is to line them all up based on when they had a certain common minimum number of cases, say 10. We will filter on a condition again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I could just type 100 in every line below, but this way if I want to experiment with a different value\n",
    "# I can edit just 1 line, instead of having to edit a line for every country (especially as countries are added)\n",
    "min_cases = 100\n",
    "USAsh = USA[ USA['total_cases'] >= min_cases ]  # 'sh' for shift\n",
    "ITAsh = ITA[ ITA['total_cases'] >= min_cases ]\n",
    "SWEsh = SWE[ SWE['total_cases'] >= min_cases ]\n",
    "KORsh = KOR[ KOR['total_cases'] >= min_cases ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAsh['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAsh['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITAsh['date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAsh['date'].min() - ITAsh['date'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see above that Italy reached 100 cases on Feb 24, 8 days before the US on Mar 3. (And that date objects can be subtracted!)\n",
    "\n",
    "Here are all the dates where these countries reached 100 cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAt0 = USAsh['date'].min()\n",
    "ITAt0 = ITAsh['date'].min()\n",
    "SWEt0 = SWEsh['date'].min()\n",
    "KORt0 = KORsh['date'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like we were able to simply multiply and divide the entire 'new_cases' Series by constant numbers, we can subtract the start date from the date Series, yielding number of days since 100 cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAsh['date'] - USAt0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAshX = USAsh['date'] - USAt0\n",
    "USAshY = USAsh['new_cases'].rolling(window=7).mean()/331\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(USAshX, USAshY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that plot goes from 0 to 2.5e16. Even though the description of `USAsh['date'] - USAt0` above says 'days', matplotlib is interpreting it as milliseconds. We can fix this by forcing conversion to days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAshX = (USAsh['date'] - USAt0).astype('timedelta64[D]')\n",
    "USAshX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(USAshX, USAshY)\n",
    "plt.plot((ITAsh['date']-ITAt0).astype('timedelta64[D]'), ITAsh['new_cases'].rolling(window=7).mean()/60)  \n",
    "plt.plot((SWEsh['date']-SWEt0).astype('timedelta64[D]'), SWEsh['new_cases'].rolling(window=7).mean()/10) \n",
    "plt.plot((KORsh['date']-KORt0).astype('timedelta64[D]'), KORsh['new_cases'].rolling(window=7).mean()/51)\n",
    "plt.legend(['USA', 'Italy', 'Sweden', 'South Korea'])\n",
    "plt.xlim( (0, 300) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

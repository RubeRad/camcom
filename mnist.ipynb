{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Notebook for MNIST neural network\n",
    "This is a Jupyter Python notebook, which is a collection of cells. Each cell is either of type 'markdown' (formatted text, like this cell) or code (python, grey background). The two most important rules of Jupyter Notebooks are:\n",
    "1. ***SHIFT-ENTER*** will cause the current cell to execute. \n",
    "  - For Markdown cells, 'execute' means render the formatting.\n",
    "  - For Code cells, 'execute' means run the python.\n",
    "  - Some Code cells take a while to execute, watch for the * to change to a number\n",
    "1. Any cell can be edited and re-executed.\n",
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "This first code cell includes import statements, which set up libraries of ready-to-go capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random                    # so we can display random images from the dataset\n",
    "import numpy as np               # numpy is everything with arrays and matrices, 'np' is a commonly-used nickname\n",
    "import matplotlib.pyplot as plt  # most common python graphing library\n",
    "import tensorflow as tf          # tensorflow is a deep learning framework.\n",
    "from   tensorflow import keras   # tensorflow.keras offers higher-level control of common tensorflow tasks\n",
    "from sklearn import metrics      # we get the 'confusion_matrix' function from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tensorflow keras library includes some datasets for training. The Modified National Institute of Standards and Technology (MNIST) dataset is 70000 images of handwritten numerical digits; each a 28x28 pixel image, and corresponding labels specifying the right answer for each.\n",
    "\n",
    "The dataset is pre-divided into 60000 images for training the neural network, and 10000 held back from the training set for independent testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "print(len(train_images), 'training images')\n",
    "print(len(test_images),  'test images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a little data prep here, we scale the pixel values from the range 0..255 to 0..1.0 (numpy makes it simple, every value in the 28x28 array gets scaled by the one divisor).\n",
    "`class_names` are string/text labels '0'...'9' corresponding to the numerical labels 0-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0  # rescale from 0..255 to 0..1.0\n",
    "test_images  = test_images  / 255.0 \n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Data\n",
    "Let's take a look at what some of these handwritten digits look like. This python code plots 25 of them in a 5x5 grid. In the middle of the loop you can switch between `which=i` and `which=random...` to control which 25 get displayed.\n",
    "\n",
    "If you display enough random digits, can you find some that look ambiguous and might be difficult? Make a note of the index, we can see later how the network did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell shows 5x5 training images (first 25 or random 25)\n",
    "plt.figure(figsize=(10,10))  # 10x10 'inches'\n",
    "for i in range(25):          # i = 0...24\n",
    "    plt.subplot(5,5, i+1)    # in a 5x5 grid, setup subplot 1...25\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])           # don't use xticks, yticks, or grid\n",
    "    plt.yticks([])\n",
    "    which = i                                       # show the ith training image\n",
    "    #which = random.randint(0,len(train_images)-1)  # show a random image\n",
    "    plt.imshow(train_images[which], cmap=plt.cm.binary) # show image in plot\n",
    "    caption = 'train[{}] is a {}'.format(which, train_labels[which])\n",
    "    plt.xlabel(caption)        # caption with corresp. label\n",
    "plt.show()  # after all 25 subplots are set up, show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Analysis\n",
    "### Structure the Network\n",
    "This is where we set up the structure of the neural network, and run the training.\n",
    "\n",
    "The first `Flatten` layer maps the individual pixel values from their 28x28 grid to an array of 784 values.\n",
    "\n",
    "The next layer is `Dense`, which means an arc from each of the 784 first-layer nodes, to every 2nd-layer nodes. `relu` is the most common 'activation function', and all it does is check whether the sum of scaled/biased inputs is positive or not. If it is positive, it 'fires' by outputting that value. If it is negative, it doesn't fire.\n",
    "\n",
    "The final layer (also `Dense`) must have 10 nodes, because we are classifying the 10 different digits. `softmax` takes the 10 numerical values that accumulate in the 10 nodes, and rescales them so they are positive and sum to 1. This way we can interpret them as probabilities.\n",
    "\n",
    "Note for the middle layer we can choose more or fewer nodes, but the outer layers have to fit the input and output. Also we could add more intermediate layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),   # input  layer; one node per pixel\n",
    "    keras.layers.Dense(16, activation='relu'),    # middle layer; may be changed to more nodes\n",
    "    keras.layers.Dense(10, activation='softmax')  # output layer; must have 10 nodes because 10 digits\n",
    "])\n",
    "\n",
    "# 'compile' basically means get ready to run\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network\n",
    "This is where the computation happens:\n",
    "- Forward-propagation from pixel inputs through the network, to scores in the output layer\n",
    "- Comparison of scores to truth, yielding errors\n",
    "- Back-propagation from errors to update coefficients in the network\n",
    "\n",
    "The 'accuracy' is the percentage of the 60000 training images predicted correctly. 'loss' is more complicated than simply percent wrong. \n",
    "\n",
    "The number of training epochs can be increased until convergence (the model stops improving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(train_images, \n",
    "                    train_labels, \n",
    "                    epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Network\n",
    "Now that the model is trained (the network coefficients have been fit to the training data), we test it by evaluating on the test images it has never seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Individual Results\n",
    "Now that we have applied the trained model to predict classifications for all the test data, let's take a look at a few to see how they compare to truth (the provided labels).\n",
    "\n",
    "### Output Layer Prediction Scores\n",
    "Set `which` variously and run the following cells to investigate.\n",
    "\n",
    "This first cell looks at the predictions array (the 10 numbers in the final layer of the network, after pushing the image through). The largest value is what digit is predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is the index of the first test image (python always counts starting from 0 not 1)\n",
    "which=0  # edit this to examine a specific \n",
    "# uncomment this to choose a random test case\n",
    "#which = random.randint(0,len(test_images)-1\n",
    "\n",
    "preds = predictions[which]    # grab this prediction, which is a 10-vector of scores from the final layer\n",
    "print('Predictions:', preds)  # let's see what it looks like!\n",
    "ansa = test_labels[which]     # this is the right answer\n",
    "pred = np.argmax(preds)       # 'max' is the largest *value* in preds, we want the *index* max lives at\n",
    "print('Correct answer is:    ', ansa)\n",
    "print('Largest prediction is:', pred)\n",
    "if pred == ansa:\n",
    "    print('Prediction is CORRECT')\n",
    "else:\n",
    "    print('Prediction is WRONG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Image\n",
    "This cell shows the image for test data 'which', using matplotlib similarly to above. Does it look like the prediction? If the prediction is wrong, does it make sense why it could have chosen that wrong prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2)) # similar matplotlib setup as above to simply show the pixels \n",
    "plt.grid(False)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(test_images[which], cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Prediction Scores\n",
    "This cell plots the predictions as a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,2))\n",
    "plt.grid(False)\n",
    "plt.xticks(range(10)) # xticks at 0,1,...9, matching the digit labels\n",
    "#plt.yticks([])       # don't eliminate yticks, let them show percentages\n",
    "barplot = plt.bar(range(10), preds, color=\"gray\")\n",
    "# remember 'pred' and 'ansa' that were set a few cells above?\n",
    "# re-execute this cell with either/both of the following lines active\n",
    "#barplot[pred].set_color('red')\n",
    "#barplot[ansa].set_color('blue')\n",
    "# what happens if pred==ansa vs if pred!=ansa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the cells above, setting which to a different index (any of the test images 0...9999), looking at the results for various test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Here is the list of all the correct answers (most not printed, because 10,000 is too long!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels # these are the correct answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, each prediction is an array of 10 floating point numbers. This cell applies `argmax` to each to get the index of the largest score in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = predictions.argmax(axis=1) # these are the predictions; the index of the largest score for each test\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, first three predictions and the last three predictions match the truth. But since accuracy was not 100%, there are some mismatches in those 9994 that are not printed. \n",
    "\n",
    "The 'confusion matrix' generated by the next cell details which numbers were mistaken for which. The rows of the matrix mean 'which digit it actually is'. The columns mean 'which digit was predicted'. \n",
    "\n",
    "What is the meaning of the large diagonal values? Other than the upper-left value, what's the largest value in the first column? What does it mean? What's the largest off-diagonal value, and what does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize groups of results\n",
    "Below is more complex code that graphs a large number of test results, with the bar graph red to highlight wrong answers.\n",
    "\n",
    "The cells with `def` create functions (python analogues of Snap! custom blocks), and only have to be run once. The last block can be rerun many times, especially if `which` is set to random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots one image with a blue or red caption\n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)  # this shows the pixels\n",
    "\n",
    "  # the rest of this assembles the caption text\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "  plt.xlabel(\"test {} {:2.0f}% ({})\".format(i,\n",
    "                                100*np.max(predictions_array), # 100* turns fractions into %\n",
    "                                class_names[true_label]),\n",
    "                                color=color)                   # color is used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the corresponding bar graph, red if it's wrong\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array, true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  #plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This uses the functions above to graph images and bar graphs in a grid.\n",
    "# In the middle again choose either which=i for the first results, or which=random\n",
    "num_cols=4 # twice as many columns really, because a digit and a bar graph for each\n",
    "num_rows=6 # freals this many rows\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    which = i # as before, leave this for sequential, or uncomment the next line for random\n",
    "    #which = random.randint(0, len(test_images)-1)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(which, predictions[which], test_labels[which], test_images[which])\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(which, predictions[which], test_labels)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
